{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import sklearn.ensemble as ske\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data = pd.read_csv('data.csv', sep='|')\n",
    "X = data.drop(['Name', 'md5', 'legitimate'], axis=1).values\n",
    "y = data['legitimate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Researching important feature based on 54 total features\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Researching important feature based on %i total features\\n' % X.shape[1])\n",
    "\n",
    "fsel = ske.ExtraTreesClassifier().fit(X, y)\n",
    "model = SelectFromModel(fsel, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nb_features = X_new.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.2)\n",
    "\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 features identified as important:\n",
      "1. feature DllCharacteristics (0.150006)\n",
      "2. feature Machine (0.096744)\n",
      "3. feature Characteristics (0.078339)\n",
      "4. feature VersionInformationSize (0.064946)\n",
      "5. feature SectionsMaxEntropy (0.062634)\n",
      "6. feature Subsystem (0.059955)\n",
      "7. feature MajorSubsystemVersion (0.058530)\n",
      "8. feature ImageBase (0.056111)\n",
      "9. feature SizeOfOptionalHeader (0.050628)\n",
      "10. feature ResourcesMinEntropy (0.040687)\n",
      "11. feature ResourcesMaxEntropy (0.040418)\n",
      "12. feature MajorOperatingSystemVersion (0.026422)\n"
     ]
    }
   ],
   "source": [
    "print('%i features identified as important:' % nb_features)\n",
    "\n",
    "indices = np.argsort(fsel.feature_importances_)[::-1][:nb_features]\n",
    "for f in range(nb_features):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, data.columns[2+indices[f]], fsel.feature_importances_[indices[f]]))\n",
    "\n",
    "for f in sorted(np.argsort(fsel.feature_importances_)[::-1][:nb_features]):\n",
    "    features.append(data.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now testing algorithms\n",
      "DecisionTree : 99.127128 %\n",
      "RandomForest : 99.391525 %\n",
      "GradientBoosting : 98.779428 %\n",
      "AdaBoost : 98.525896 %\n",
      "GNB : 70.365809 %\n"
     ]
    }
   ],
   "source": [
    "algorithms = {\n",
    "        \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=10),\n",
    "        \"RandomForest\": ske.RandomForestClassifier(n_estimators=50),\n",
    "        \"GradientBoosting\": ske.GradientBoostingClassifier(n_estimators=50),\n",
    "        \"AdaBoost\": ske.AdaBoostClassifier(n_estimators=100),\n",
    "        \"GNB\": GaussianNB()\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "print(\"\\nNow testing algorithms\")\n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(\"%s : %f %%\" % (algo, score*100))\n",
    "    results[algo] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Algorithm with highest accuracy on train/test is RandomForest with a 99.391525 % success\n"
     ]
    }
   ],
   "source": [
    "winner = max(results, key=results.get)\n",
    "print('\\n Algorithm with highest accuracy on train/test is %s with a %f %% success' % (winner, results[winner]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving algorithm and feature list in classifier directory...\n",
      "Saved\n"
     ]
    }
   ],
   "source": [
    "print('Saving algorithm and feature list in classifier directory...')\n",
    "joblib.dump(algorithms[winner], 'classifier/classifier.pkl')\n",
    "open('classifier/features.pkl', 'wb').write(pickle.dumps(features))\n",
    "print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate : 0.458102 %\n",
      "False negative rate : 0.965534 %\n"
     ]
    }
   ],
   "source": [
    "clf = algorithms[winner]\n",
    "res = clf.predict(X_test)\n",
    "mt = confusion_matrix(y_test, res)\n",
    "print(\"False positive rate : %f %%\" % ((mt[0][1] / float(sum(mt[0])))*100))\n",
    "print('False negative rate : %f %%' % ( (mt[1][0] / float(sum(mt[1]))*100)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
